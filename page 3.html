<!DOCTYPE html>
<html lang="en">

<meta http-equiv="content-type" content="text/html;charset=UTF-8" />
<head>
      <meta charset="utf-8"/>
      <title>Artificial intelligence</title>

</head>
<body>
                <h1 style="font-size:80px; color:green; padding-bottom: 12px"><span class="default-color">Artificial intelligence</span></h1>
				<h1  style="font-size:40px; color: red " > Literature review 2</h1>
			<p style="font-size:20px;" > 
Deep learning while flashy is really just a term to describe certain types of neural networksand related algorithms that consume often very raw input data. They process this datathrough many layers of nonlinear transformations of the input data in order to calculate a
target output.<br/>
Unsupervised feature extraction is also an area where deep learning excels. Feature extraction is when an algorithm is able to automatically derive or construct meaningful features of the data to be used for further learning, generalization, and understanding.The burden is traditionally on the data scientist or programmer to carry out the feature extraction process in most other machine learning approaches, along with feature selection and engineering.<br/>
Feature extraction usually involves some amount dimensionality reduction as well,which is reducing the amount of input features and data required to generate meaningful results. This has many benefits, which include simplification, computational and memory power reduction, and so on. Programmers would train a neural network to detect an object or phoneme by blitzing the network with digitized versions of images containing
those objects or sound waves containing those phonemes. If the network didn’t accurately recognize a particular pattern, an algorithm would adjust the weights.The eventual goal of this training was to get the network to consistently recognize the patternsin speech or sets of images that we humans know as, say, the phoneme “d” or the image of a dog. This is much the same way a child learns what a dog is by noticing
the details of head shape, behavior, and the like in furry, barking animals that other people call dogs.
Machine learning came directly from minds of the early AI crowd, and the algorithmic approaches over the yearsincluded decision tree learning, inductive logic programming. clustering, reinforcement learning, and Bayesian networks among others.As we know, none achieved the ultimate goal of General AI, and even Narrow AI was mostly out of reach with early machine learning approaches.<br/>
As it turned out, one of the very best application areas for machine learning for many years was computer vision, though it still required a great deal of hand-coding to get the job done. People would go in and write hand-coded classifiers like edge detection filters so the program could identify where an object started and stopped;shape detection to determine if it had eight sides; a classifier to recognize the letters “S-T-O-P.” From all those hand-coded classifiers they would develop algorithmsto make sense of the image and “learn” to determine whether it was a stop sign.<br/>
Good, but not mind-bendingly great. Especially on a foggy day when the sign isn’t perfectly visible, or a tree obscures part of it. There’s a reason computer vision and image detection didn’t come close to rivaling humans until very recently, it was too
brittle and too prone to error.Time, and the right learning algorithms made all the difference.
    </p>
    <h1>History of artificial intelligence <h1 style="color: red">Table</h1> </h1>
           <table style="width: 100%; border: 1px solid black">
    <tr style=" border: 1px solid black">
        <th style=" border: 1px solid black">1991</th>
        <th style=" border: 1px solid black">U.S. forces deploy DART, an automated logistics planning and scheduling tool, during the Gulf War.</th>
        </tr>
        <tr>
        <th style=" border: 1px solid black">1997
</th>
        <th style=" border: 1px solid black">IBM's Deep Blue beats world chess champion Gary Kasparov
</th>
        </tr>
                <tr style=" border: 1px solid black">
        <th style=" border: 1px solid black">2005</th>
        <th style=" border: 1px solid black">STANLEY, a self-driving car, wins the DARPA Grand Challenge.

The U.S. military begins investing in autonomous robots like Boston Dynamic's "Big Dog" and iRobot's "PackBot."
</th>
        </tr> <tr style=" border: 1px solid black">
        <th style=" border: 1px solid black">2008</th>
        <th style=" border: 1px solid black">Google makes breakthroughs in speech recognition and introduces the feature in its iPhone app. </th>
        </tr> <tr style=" border: 1px solid black">
        <th style=" border: 1px solid black">2011
</th>
        <th style=" border: 1px solid black">IBM's Watson trounces the competition on Jeopardy!.  
</th>
        </tr> <tr style=" border: 1px solid black">
        <th style=" border: 1px solid black">2012
</th>
        <th style=" border: 1px solid black">Andrew Ng, founder of the Google Brain Deep Learning project, feeds a neural network using deep learning algorithms 10 million YouTube videos as a training set. The neural network learned to recognize a cat without being told what a cat is, ushering in breakthrough era for neural networks and deep learning funding.
</th>
        </tr> <tr style=" border: 1px solid black">
        <th style=" border: 1px solid black">2014</th>
        <th style=" border: 1px solid black">Google makes first self-driving car to pass a state driving test. 
</th>
        </tr> <tr style=" border: 1px solid black">
        <th style=" border: 1px solid black">2016</th>
        <th style=" border: 1px solid black">Google DeepMind's AlphaGo defeats world champion Go player Lee Sedol. The complexity of the ancient Chinese game was seen as a major hurdle to clear in AI</th>
        </tr>
    </table>
    </body>               
</html>